{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "107062566 Yu-Cheng Huang, requires tqdm and the latest tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "\n",
    "class Corpus:\n",
    "    def __init__(self):\n",
    "        self.word2cnt = defaultdict(int)\n",
    "        self.word2idx = dict()\n",
    "        self.idx2word = dict()\n",
    "        self.special = ['SOS', 'EOS', 'UKN', 'PAD']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        self.word2cnt[word] += 1\n",
    "\n",
    "    def add_words(self, words):\n",
    "        for word in words:\n",
    "            self.add_word(word)\n",
    "\n",
    "    def freeze(self):\n",
    "        rare_words = [word for word, cnt in self.word2cnt.items() if cnt < 5]\n",
    "        for word in rare_words:\n",
    "            del self.word2cnt[word]\n",
    "            \n",
    "        self.word2idx = dict()\n",
    "        self.idx2word = dict()\n",
    "        freq_words = self.special + list(self.word2cnt.keys())\n",
    "        for idx, word in enumerate(freq_words):\n",
    "            self.word2idx[word] = idx\n",
    "            self.idx2word[idx] = word\n",
    "    \n",
    "    def transform(self, tokens):\n",
    "        ukn = self.word2idx['UKN']\n",
    "        pad = self.word2idx['PAD']\n",
    "        result = [self.word2idx.get(t, ukn) for t in tokens]\n",
    "        n_need = MAX_LENGTH - len(result)\n",
    "        if n_need > 0:\n",
    "            result.extend([pad] * n_need)\n",
    "        return result\n",
    "    \n",
    "    def restore(self, idxs):\n",
    "        tokens = [self.idx2word[idx] for idx in idxs]\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 304714/304714 [00:03<00:00, 86463.98it/s]\n",
      "100%|██████████| 83098/83098 [00:00<00:00, 197302.31it/s]\n"
     ]
    }
   ],
   "source": [
    "regex = re.compile(r'[-:;,.?!\\'\\\"+*/]*')\n",
    "line_data = dict() # line_id -> tokens\n",
    "with open('./data/movie_lines.txt', errors='ignore') as f:\n",
    "    data = f.read().split('\\n')\n",
    "    for line in tqdm(data):\n",
    "        line = line.split(' ')\n",
    "        line_id = line[0]\n",
    "        tokens = [t for t in line[8:] if t]\n",
    "        tokens = [regex.sub('', t.lower()) for t in tokens]\n",
    "        line_data[line_id] = tokens\n",
    "\n",
    "corpus = Corpus()\n",
    "ques = []\n",
    "anss = []\n",
    "with open('./data/movie_conversations.txt', errors='ignore') as f:\n",
    "    data = f.read().split('\\n')\n",
    "    for line in tqdm(data):\n",
    "        idxs = re.findall(r'L\\d+', line)\n",
    "        for que_idx, ans_idx in zip(idxs[:-1], idxs[1:]):\n",
    "            que = line_data[que_idx]\n",
    "            ans = line_data[ans_idx]\n",
    "            if len(que) < MAX_LENGTH - 1 and len(ans) < MAX_LENGTH - 1:\n",
    "                corpus.add_words(que)\n",
    "                corpus.add_words(ans)\n",
    "                ques.append(que)\n",
    "                anss.append(ans)\n",
    "\n",
    "corpus.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 10, 256) int32\n",
      "(307, 10, 256) int32\n",
      "(307, 10, 256) int32\n",
      "(307, 10, 256) float32\n",
      "6205\n"
     ]
    }
   ],
   "source": [
    "encoder_inp = []\n",
    "decoder_inp = []\n",
    "decoder_true = []\n",
    "decoder_mask = []\n",
    "for que, ans in zip(ques, anss):\n",
    "    encoder_inp.append(np.int32(corpus.transform(que + ['EOS'])))\n",
    "    decoder_inp.append(np.int32(corpus.transform(['SOS'] + ans)))\n",
    "    decoder_true.append(np.int32(corpus.transform(ans + ['EOS'])))\n",
    "    decoder_mask.append(np.float32([1 if t >= 4 else 0 for t in decoder_true[-1]]))\n",
    "\n",
    "encoder_inp = np.stack(encoder_inp, axis=0)\n",
    "decoder_inp = np.stack(decoder_inp, axis=0)\n",
    "decoder_true = np.stack(decoder_true, axis=0)             \n",
    "decoder_mask = np.stack(decoder_mask, axis=0) \n",
    "\n",
    "def batchify(arr):\n",
    "    n_part = len(arr) // BATCH_SIZE\n",
    "    arr = np.split(arr[:n_part * BATCH_SIZE], n_part, axis=0)\n",
    "    arr = np.stack(arr, axis=0)\n",
    "    return arr\n",
    "\n",
    "def transpose(arr):\n",
    "    return np.transpose(arr, (0, 2, 1))\n",
    "                \n",
    "encoder_inp = transpose(batchify(encoder_inp))\n",
    "decoder_inp = transpose(batchify(decoder_inp))\n",
    "decoder_true = transpose(batchify(decoder_true))\n",
    "decoder_mask = transpose(batchify(decoder_mask))\n",
    "\n",
    "# [n_part, seq_len, batch_size]\n",
    "print(encoder_inp.shape, encoder_inp.dtype)\n",
    "print(decoder_inp.shape, decoder_inp.dtype)\n",
    "print(decoder_true.shape, decoder_true.dtype)\n",
    "print(decoder_mask.shape, decoder_mask.dtype)\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq:\n",
    "    def __init__(self):\n",
    "        dict_sz = len(corpus)\n",
    "        \n",
    "        with tf.variable_scope('var'):\n",
    "            self.enc_inp = [tf.placeholder(tf.int32, [None]) for _ in range(MAX_LENGTH)]\n",
    "            self.dec_inp = [tf.placeholder(tf.int32, [None]) for _ in range(MAX_LENGTH)]\n",
    "            self.dec_true = [tf.placeholder(tf.int32, [None]) for _ in range(MAX_LENGTH)]\n",
    "            self.dec_mask = [tf.placeholder(tf.float32, [None]) for _ in range(MAX_LENGTH)]\n",
    "        \n",
    "        with tf.variable_scope('rnn'):\n",
    "            self.rnn_cell_tf = tf.contrib.rnn.LSTMCell(512)\n",
    "            self.dec_pred_tf, _ = tf.contrib.legacy_seq2seq.embedding_attention_seq2seq(\n",
    "                self.enc_inp, self.dec_inp, self.rnn_cell_tf, dict_sz, dict_sz, 300\n",
    "            )\n",
    "            \n",
    "        with tf.variable_scope('rnn', reuse=True):\n",
    "            self.rnn_cell = tf.contrib.rnn.LSTMCell(512, reuse=True)\n",
    "            self.dec_pred, _ = tf.contrib.legacy_seq2seq.embedding_attention_seq2seq(\n",
    "                self.enc_inp, self.dec_inp, self.rnn_cell, dict_sz, dict_sz, 300, feed_previous=True\n",
    "            )\n",
    "            \n",
    "        with tf.variable_scope('loss'):\n",
    "            self.loss = tf.reduce_mean(tf.contrib.legacy_seq2seq.sequence_loss_by_example(\n",
    "                self.dec_pred_tf, self.dec_true, self.dec_mask\n",
    "            ))\n",
    "            self.optimizer = tf.train.AdamOptimizer(0.002).minimize(self.loss)\n",
    "            \n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        self.sess = tf.Session(config=config)\n",
    "        self.saver = tf.train.Saver()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def train_step(self, encoder_inp, decoder_inp, decoder_true, decoder_mask):\n",
    "        feed_dict = dict()\n",
    "        for i in range(MAX_LENGTH):\n",
    "            feed_dict[self.enc_inp[i]] = encoder_inp[i]\n",
    "            feed_dict[self.dec_inp[i]] = decoder_inp[i]\n",
    "            feed_dict[self.dec_true[i]] = decoder_true[i]\n",
    "            feed_dict[self.dec_mask[i]] = decoder_mask[i]\n",
    "        loss, _ = self.sess.run([self.loss, self.optimizer], feed_dict)\n",
    "        return loss\n",
    "    \n",
    "    def predict(self, encoder_inp):\n",
    "        feed_dict = dict()\n",
    "        for i in range(MAX_LENGTH):\n",
    "            feed_dict[self.enc_inp[i]] = encoder_inp[i]\n",
    "            if i == 0:\n",
    "                feed_dict[self.dec_inp[i]] = np.full(encoder_inp.shape[1], corpus.word2idx['SOS'])\n",
    "            else:\n",
    "                feed_dict[self.dec_inp[i]] = np.zeros(encoder_inp.shape[1])\n",
    "                \n",
    "        pred = self.sess.run(self.dec_pred, feed_dict)\n",
    "        pred = np.float32(pred) # [seq_len, batch_sizes, dict_sz]\n",
    "        pred = np.argmax(pred, axis=2)\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def save(self, e):\n",
    "        self.saver.save(self.sess, 'data/rnn_%d.ckpt'%(e+1))\n",
    "    \n",
    "    def restore(self, e):\n",
    "        self.saver.restore(self.sess, 'data/rnn_%d.ckpt'%(e))\n",
    "    \n",
    "tf.reset_default_graph()\n",
    "model = Seq2Seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This cell is executed in tmux for long training time\n",
    "# for epoch in range(50):\n",
    "#     n_step = len(encoder_inp)\n",
    "    \n",
    "#     indices = np.random.permutation(n_step)\n",
    "#     encoder_inp = encoder_inp[indices]\n",
    "#     decoder_inp = decoder_inp[indices]\n",
    "#     decoder_true = decoder_true[indices]\n",
    "#     decoder_mask = decoder_mask[indices]\n",
    "    \n",
    "#     avg_loss = 0.0\n",
    "#     with tqdm(total=n_step, desc=f'Epoch {epoch:02d}') as pbar:\n",
    "#         for i in range(n_step):\n",
    "#             loss = model.train_step(encoder_inp[i], decoder_inp[i], decoder_true[i], decoder_mask[i])\n",
    "#             avg_loss = (avg_loss * i + loss) / (i + 1)\n",
    "#             pbar.set_postfix(loss=avg_loss)\n",
    "#             pbar.update(1)\n",
    "    \n",
    "#     model.save(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from data/rnn_98.ckpt\n",
      "> hello\n",
      "< hi mike its frank  me in the bathroom where\n",
      "> how are you\n",
      "< fine watch well im feelin for you thats a better\n",
      "> where are you going\n",
      "< nowhere you were fucking around bed inn im leaving from\n",
      "> you look great\n",
      "< thanks for calling the tv lights here calling me back\n",
      "> good night\n",
      "< sleep tight its friday a good land mine land might\n"
     ]
    }
   ],
   "source": [
    "model.restore(98)\n",
    "\n",
    "ques = [\n",
    "    ['hello', 'EOS'],\n",
    "    ['how', 'are', 'you', 'EOS'],\n",
    "    ['where', 'are', 'you', 'going', 'EOS'],\n",
    "    ['you', 'look', 'great', 'EOS'],\n",
    "    ['good', 'night', 'EOS'],\n",
    "]\n",
    "ques_nd = np.int32(list(map(corpus.transform, ques))).transpose()\n",
    "anss_nd = model.predict(np.int32(ques_nd)).transpose()\n",
    "anss = list(map(corpus.restore, anss_nd))\n",
    "for que, ans in zip(ques, anss):\n",
    "    print('>', ' '.join(que[:-1]))\n",
    "    print('<', ' '.join(ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "\n",
    "資料前處理的部份我使用 regular expression 來抽取文字，然後使用 np.split 來分切成 batch。我覺得我寫了一個 corpus 的 class 做得非常好，簡化了很多邏輯，程式碼看起來就很好看~\n",
    "\n",
    "而結果的部份，model 回答的前半部份都是合理的，但之後就生成奇怪的單詞，我想這是 teacher forcing 造成的。我研究了一些網路上其他人實現的 seq2seq，發現所有人都是「機率性」地使用 teacher forcing（0.5 的機率使用，0.5 的機率使用前一個 hidden state），他們並沒有像 TA 的程式一樣「全部」使用 teacher forceing。我想這是造成 model 回答不甚理想的原因之一。\n",
    "\n",
    "同時，另一個觀察到的現像為：model 不會輸出 EOS，即使訓練資料（`decode_true`）是有包含 EOS 的。我不確定為什麼會這樣，不過這是目前我訓練出來最好的結果了。\n",
    "\n",
    "心得：tensorflow 的 rnn 怎麼這麼吃 cpu 啊…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
